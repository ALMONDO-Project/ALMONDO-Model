{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Union\n",
    "from metrics import nclusters, pwdist, lobbyist_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lobbyists = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'../results/{n_lobbyists}_lobbyistsconfig.json', 'r') as f:\n",
    "    params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p_o': 0.01, 'p_p': 0.99, 'lambda_values': [0.0, 0.5, 1.0], 'phi_values': [0.0, 0.5, 1.0], 'T': 10000, 'n_lobbyists': 2, 'lobbyists': {'0': {'m': 0, 'strategy': ''}, '1': {'m': 1, 'strategy': ''}}, 'nruns': 3}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_o = params['p_o']\n",
    "p_p = params['p_p']\n",
    "lambda_values = params['lambda_values']\n",
    "phi_values = params['phi_values']\n",
    "n_lobbyists = params['n_lobbyists']\n",
    "nruns = params['nruns']\n",
    "lobbyists_data = {int(k): {\"m\": int(v[\"m\"]), \"strategy\": v[\"strategy\"]} for k, v in params[\"lobbyists\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(trends: dict, \n",
    "            p_o: float,\n",
    "            p_p: float,\n",
    "            iteration: Union[int, str] = -1, \n",
    "            kind: str = \"probabilities\"):\n",
    "       \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            trends (dict): The computed simulation trends.\n",
    "            p_o (float): Probability of the optimistic model.\n",
    "            p_p (float): Probability of the pessimistic model.\n",
    "            iteration (int | str): The iteration number or \"last\" for final state (default: -1).\n",
    "            values (str): The type of values to extract (\"probabilities\" or \"weights\").\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(iteration, int) and -1 <= iteration < len(trends):\n",
    "            it = trends[iteration]['iteration']\n",
    "            ops = np.array(list(trends[iteration]['status'].values()), dtype=float)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid iteration index: {iteration}\")\n",
    "\n",
    "        # Compute values based on type\n",
    "        if kind == 'probabilities':\n",
    "            ops = p_o * ops + p_p * (1 - ops)\n",
    "            ops = np.array(ops, dtype=float)\n",
    "        elif kind == 'weights':\n",
    "            np.array(ops, dtype=float)\n",
    "        else:\n",
    "            raise ValueError(\"`values` must be either 'probabilities' or 'weights'.\")\n",
    "        \n",
    "        return ops, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cceec1945b342d7aa8f6302c652b2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/54 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/user_data/users/pansanella/github/almondo-tweets-retrieval/model/metrics/metrics.py:114: RuntimeWarning: divide by zero encountered in divide\n",
      "  (1 - p_lob) * np.log((1 - p_lob) / (1 - opinions))\n",
      "/media/user_data/users/pansanella/github/almondo-tweets-retrieval/model/metrics/metrics.py:114: RuntimeWarning: invalid value encountered in log\n",
      "  (1 - p_lob) * np.log((1 - p_lob) / (1 - opinions))\n",
      "/home/pansanella/mydata/github/almondo-tweets-retrieval/twitter-venv/lib/python3.11/site-packages/numpy/core/_methods.py:173: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm  # Use tqdm for Jupyter Notebook\n",
    "\n",
    "kinds = ['weights', 'probabilities']\n",
    "\n",
    "# Total iterations for tqdm\n",
    "total_iterations = len(kinds) * len(params['lambda_values']) * len(params['phi_values']) * params['nruns']\n",
    "\n",
    "with tqdm(total=total_iterations, desc=\"Processing\", unit=\"iteration\") as pbar:\n",
    "    for kind in kinds:\n",
    "        for _, (lambda_v, phi_v) in enumerate([(l, p) for l in params['lambda_values'] for p in params['phi_values']]):    \n",
    "            \n",
    "            path = os.path.join(f'../results/{n_lobbyists}_lobbyists/', f'{lambda_v}_{phi_v}/')    \n",
    "\n",
    "            metrics = {\n",
    "                'effective_number_clusters': [],\n",
    "                'number_iterations': [],\n",
    "                'average_pairwise_distance': [],\n",
    "                'average_opinions': [],\n",
    "                'std_opinions': [],\n",
    "                'lobbyists_performance': {k: [] for k in range(n_lobbyists)}\n",
    "            }\n",
    "            \n",
    "            avg_metrics = {\n",
    "                'effective_number_clusters': {'avg': -1, 'std': -1},\n",
    "                'number_iterations': {'avg': -1, 'std': -1},\n",
    "                'average_pairwise_distance': {'avg': -1, 'std': -1},\n",
    "                'average_opinions': {'avg': -1, 'std': -1},\n",
    "                'std_opinions': {'avg': -1, 'std': -1},\n",
    "                'lobbyists_performance': {k: {'avg': -1, 'std': -1} for k in range(n_lobbyists)}\n",
    "            }\n",
    "\n",
    "            for run in range(params['nruns']):\n",
    "                runpath = os.path.join(path, str(run))\n",
    "                \n",
    "                with open(runpath+'/status.json', 'r') as f:\n",
    "                    trends = json.load(f)\n",
    "                \n",
    "                ops, it = get_data(trends, p_o, p_p, kind=kind)\n",
    "                \n",
    "                metrics['effective_number_clusters'].append(nclusters(ops, 0.0001))\n",
    "                metrics['number_iterations'].append(it)\n",
    "                metrics['average_pairwise_distance'].append(pwdist(ops))\n",
    "                metrics['average_opinions'].append(np.array(ops).mean())\n",
    "                metrics['std_opinions'].append(np.array(ops).std())\n",
    "\n",
    "                for id, lob in lobbyists_data.items():\n",
    "                    metrics['lobbyists_performance'][id].append(lobbyist_performance(ops, lob['m'], p_o, p_p))\n",
    "                    \n",
    "                for k, v in metrics.items():\n",
    "                    if k != 'lobbyists_performance':\n",
    "                        avg = np.array(v).mean()\n",
    "                        std = np.array(v).std()\n",
    "                        avg_metrics[k]['avg'] = avg\n",
    "                        avg_metrics[k]['std'] = std\n",
    "                    else:\n",
    "                        for id in range(n_lobbyists):\n",
    "                            avg = np.array(v[id]).mean()\n",
    "                            std = np.array(v[id]).std()\n",
    "                            avg_metrics[k][id]['avg'] = avg\n",
    "                            avg_metrics[k][id]['std'] = std\n",
    "                pbar.update(1)  \n",
    "\n",
    "            with open(path+'metrics_distributions.json', 'w') as f:\n",
    "                json.dump(metrics, f)\n",
    "            \n",
    "            with open(path+'average_metrics.json', 'w') as f:\n",
    "                json.dump(avg_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
